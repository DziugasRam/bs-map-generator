{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import random\n",
    "from data_loader import full_load_map, data_dir, load_map, Note\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1470258369\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_multi_process(map_folders):\n",
    "    map_folders = [map_folder.decode('UTF-8') for map_folder in map_folders]\n",
    "    max_workers = 18\n",
    "    items_in_queue = max_workers * 5\n",
    "    queued_maps = items_in_queue\n",
    "    cancel = False\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        map_tasks = [(executor.submit(full_load_map, map_folder), map_folder) for map_folder in map_folders[:items_in_queue]]\n",
    "        while len(map_tasks) > 0:\n",
    "            map_task, map_folder = map_tasks.pop(0)\n",
    "            try:\n",
    "                if cancel:\n",
    "                    map_task.cancel()\n",
    "                    continue\n",
    "                results = map_task.result()\n",
    "                for result in results:\n",
    "                    x_context_prev_audio, x_context_prev_notes, x_context_audio, y_context_notes, z_timing_counts, z_note_counts, z_note_pos_counts, z_acc_prediction, z_speed_prediction = result\n",
    "                    yield (x_context_prev_audio), (x_context_prev_notes), (x_context_audio), z_timing_counts, z_note_counts/20, z_note_pos_counts/10, z_acc_prediction, z_speed_prediction, (y_context_notes)\n",
    "            except InterruptedError as ke:\n",
    "                cancel = True\n",
    "            except Exception as exc:\n",
    "                if str(exc) != \"'_version'\" and str(exc) != 'not v2':\n",
    "                    print(map_folder)\n",
    "                    print(exc)\n",
    "                    traceback.print_exc()\n",
    "            finally:\n",
    "                if not cancel:\n",
    "                    queued_maps += 1\n",
    "                    if queued_maps < len(map_folders):\n",
    "                        map_tasks.append((executor.submit(full_load_map, map_folders[queued_maps]), map_folders[queued_maps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ds_for_files(map_folders, batch_size, name, cache=False, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_generator(data_generator_multi_process, args=[map_folders], output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 2, 87, 129), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 40, 25), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 87, 129), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 40, 25), dtype=tf.float32),\n",
    "        # tf.TensorSpec(shape=(None, 1025, 44), dtype=tf.float32),\n",
    "        # tf.TensorSpec(shape=(None, 35), dtype=tf.float32),\n",
    "    ))\n",
    "    ds = ds.flat_map(lambda x1, x2, x3, x4, x5, x6, x7, x8, y: tf.data.Dataset.from_tensor_slices((x1, x2, x3, x4, x5, x6, x7, x8, y)))\n",
    "    ds = ds.prefetch(20000)\n",
    "\n",
    "    if cache:\n",
    "        # ds = ds.cache()\n",
    "        ds = ds.cache(f\"./somethingsomething/{name}\")\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(25000, reshuffle_each_iteration=True)\n",
    "        # ds = ds.shuffle(len([v for v in ds]), reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(256)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I currently cache the entire dataset, since the data loading part is quite compute intensive. Added a limit of 50 maps to avoid running out of ram on a test run.\n",
    "maps = [path.replace(\"\\\\\", \"/\") for path in glob.glob(\"../data/maps/*\")]\n",
    "random.shuffle(maps)\n",
    "# maps = maps[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "val_split = 0.1\n",
    "train_ds = create_ds_for_files(maps[int(len(maps)*val_split):], batch_size, \"train\", True, True)\n",
    "val_ds = create_ds_for_files(maps[:int(len(maps)*val_split)], batch_size, \"val\", True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1766it [04:33,  6.46it/s]\n",
      "208it [00:37,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# preload the dataset into cache to keep the data loading errors away from the training logs\n",
    "discard_value = [0 for v in tqdm(train_ds)]\n",
    "\n",
    "discard_value = [0 for v in tqdm(val_ds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per position loss balance, might not be relevent with the updatd note format\n",
    "# # with tf.device('/CPU:0'):\n",
    "# out_value_counts = tf.constant([0]*49, dtype=tf.float32)\n",
    "# for v_batch in tqdm(train_ds):\n",
    "#     out_value_counts = out_value_counts + tf.reduce_sum(v_batch[-1], axis=[0, 1])\n",
    "# # for i, ovc in enumerate(out_value_counts):\n",
    "# #     print(f\"{(i-1)} {ovc}\")\n",
    "# note_poss_loss_balance = tf.expand_dims(tf.expand_dims(1/tf.maximum(out_value_counts[1:] * (1/np.max(out_value_counts[1:])*10), 1), 0), 0)\n",
    "# note_poss_loss_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_block():\n",
    "    input_audio = tf.keras.Input(shape=(87, 129, 1), dtype=\"float32\")\n",
    "    l = input_audio\n",
    "    l = tf.keras.layers.Conv2D(128, 5, activation=\"relu\", padding=\"same\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(l)\n",
    "    l = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(1, 2))(l)\n",
    "    l = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(1, 2))(l)\n",
    "    l = tf.keras.layers.Reshape((40, -1))(l)\n",
    "    l = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(128, activation=\"tanh\"))(l)\n",
    "    return tf.keras.Model(input_audio, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_block_stereo():\n",
    "    l_audio_block = audio_block()\n",
    "    \n",
    "    input_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    l = input_audio\n",
    "    l = tf.keras.layers.TimeDistributed(l_audio_block)(l)\n",
    "    l = tf.keras.layers.Permute((2, 1, 3))(l)\n",
    "    l = tf.keras.layers.Reshape((40, -1))(l)\n",
    "    l = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(l)\n",
    "    l = tf.keras.layers.LSTM(64, return_sequences=True)(l)\n",
    "    return tf.keras.Model(input_audio, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_positioning_block():\n",
    "    input_timings = tf.keras.Input(shape=(2, 40, 1), dtype=\"float32\")\n",
    "    input_features = tf.keras.Input(shape=(40, 128), dtype=\"float32\")\n",
    "    \n",
    "    l_timings = tf.keras.layers.Permute((2, 1, 3))(input_timings)\n",
    "    l_timings = tf.keras.layers.Reshape((40, -1))(l_timings)\n",
    "\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_timings, input_features])\n",
    "    l = tf.keras.layers.LSTM(256, return_sequences=True)(l)\n",
    "    l = tf.keras.layers.LSTM(256, return_sequences=True)(l)\n",
    "    l_pos_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(24, activation=\"sigmoid\"))(l)\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_pos_out, l])\n",
    "    l = tf.keras.layers.LSTM(128, return_sequences=True)(l)\n",
    "    l = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(l)\n",
    "    l_angle_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(24, activation=\"linear\"))(l)\n",
    "    \n",
    "    l_pos_out = tf.keras.layers.Reshape((40, 2, -1))(l_pos_out)\n",
    "    l_pos_out = tf.keras.layers.Permute((2, 1, 3))(l_pos_out)\n",
    "    l_angle_out = tf.keras.layers.Reshape((40, 2, -1))(l_angle_out)\n",
    "    l_angle_out = tf.keras.layers.Permute((2, 1, 3))(l_angle_out)\n",
    "    \n",
    "    return tf.keras.Model([input_timings, input_features], [l_pos_out, l_angle_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    input_prev_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    input_prev_notes = tf.keras.Input(shape=(2, 40, 25), dtype=\"float32\")\n",
    "    input_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    input_acc_prediction = tf.keras.Input(shape=(1), dtype=\"float32\")\n",
    "    input_speed_prediction = tf.keras.Input(shape=(1), dtype=\"float32\")\n",
    "    input_y_note_timings = tf.keras.Input(shape=(2, 40, 1), dtype=\"float32\")\n",
    "\n",
    "    audio_l = audio_block_stereo()\n",
    "\n",
    "    l_prev_audio = audio_l(input_prev_audio)\n",
    "    l_audio = audio_l(input_audio)\n",
    "    \n",
    "    l_prev_notes = tf.keras.layers.Permute((2, 1, 3))(input_prev_notes)\n",
    "    l_prev_notes = tf.keras.layers.Reshape((40, -1))(l_prev_notes)\n",
    "    \n",
    "    l_prev = tf.keras.layers.Concatenate(axis=2)([l_prev_audio, l_prev_notes])\n",
    "    l_prev = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(l_prev)\n",
    "    l_prev = tf.keras.layers.LSTM(64)(l_prev)\n",
    "    \n",
    "    l_input_acc_prediction = tf.keras.layers.RepeatVector(40)(input_acc_prediction)\n",
    "    l_input_speed_prediction = tf.keras.layers.RepeatVector(40)(input_speed_prediction)\n",
    "    l_prev = tf.keras.layers.RepeatVector(40)(l_prev)\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_audio, l_prev, l_input_acc_prediction, l_input_speed_prediction])\n",
    "    l = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(l)\n",
    "    l = tf.keras.layers.LSTM(128, return_sequences=True)(l)\n",
    "    l_timings_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"sigmoid\"))(l)\n",
    "    l_timings_out = tf.keras.layers.Permute((2, 1))(l_timings_out)\n",
    "    l_timings_out = tf.keras.layers.Reshape((2, 40, -1))(l_timings_out)\n",
    "\n",
    "    note_positioning_l = note_positioning_block()\n",
    "    \n",
    "    l_pos_out, l_angle_out = note_positioning_l([input_y_note_timings, l])\n",
    "\n",
    "    model = tf.keras.Model(inputs = [input_prev_audio, input_prev_notes, input_audio, input_acc_prediction, input_speed_prediction, input_y_note_timings], outputs = [l_timings_out, l_pos_out, l_angle_out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 2, 87, 129,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 2, 87, 129,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 2, 40, 25)]  0           []                               \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 40, 64)       741760      ['input_11[0][0]',               \n",
      "                                                                  'input_13[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 40, 50)       0           ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 40, 114)      0           ['model_5[0][0]',                \n",
      "                                                                  'reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 40, 128)     91648       ['concatenate_4[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 64)           49408       ['bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " repeat_vector_5 (RepeatVector)  (None, 40, 64)      0           ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 40, 1)       0           ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " repeat_vector_4 (RepeatVector)  (None, 40, 1)       0           ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 40, 130)      0           ['model_5[1][0]',                \n",
      "                                                                  'repeat_vector_5[0][0]',        \n",
      "                                                                  'repeat_vector_3[0][0]',        \n",
      "                                                                  'repeat_vector_4[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 40, 256)     265216      ['concatenate_5[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 (None, 40, 128)      197120      ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 40, 2)       258         ['lstm_14[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 2, 40, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 2, 40, 1)     0           ['time_distributed_8[0][0]']     \n",
      "                                                                                                  \n",
      " model_6 (Functional)           [(None, 2, 40, 12),  1176368     ['input_16[0][0]',               \n",
      "                                 (None, 2, 40, 12)]               'lstm_14[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,521,778\n",
      "Trainable params: 2,521,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize the model\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_train_timing_loss = tf.keras.metrics.Mean(name='metric_train_timing_loss')\n",
    "metric_train_pos_loss = tf.keras.metrics.Mean(name='metric_train_pos_loss')\n",
    "metric_train_angle_loss = tf.keras.metrics.Mean(name='metric_train_angle_loss')\n",
    "metric_train_loss = tf.keras.metrics.Mean(name='metric_train_loss')\n",
    "metric_val_timing_loss = tf.keras.metrics.Mean(name='metric_val_timing_loss')\n",
    "metric_val_pos_loss = tf.keras.metrics.Mean(name='metric_val_pos_loss')\n",
    "metric_val_angle_loss = tf.keras.metrics.Mean(name='metric_val_angle_loss')\n",
    "metric_val_loss = tf.keras.metrics.Mean(name='metric_val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss\n",
    "Calculates 2 separate values:\n",
    " - timing loss - simple loss based on when the notes were placed\n",
    " - positioning loss - loss based on the position and direction of the placed note, adjusted for the number of notes that appear in different positions to avoid a massive bias towards placing most commonly appearing notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_loss(y, predictions):\n",
    "    timing_predictions, pos_predictions, angle_predictions = predictions\n",
    "    org_timing_loss_matrix = tf.square(y[:, :, :, :1] - timing_predictions) * (y[:, :, :, :1] + 0.08)\n",
    "    timing_loss_matrix = org_timing_loss_matrix\n",
    "    timing_loss = tf.reduce_mean(timing_loss_matrix) * 10\n",
    "    \n",
    "    # positioning_loss_matrix = tf.square(y[:, :, 1:] - positioning_predictions) * (y[:, :, :1]) * (y[:, :, 1:] * note_poss_loss_balance + 0.0169)\n",
    "    # positioning_loss = tf.reduce_sum(positioning_loss_matrix) / tf.reduce_sum(y[:, :, 1:]) * 0.5\n",
    "    \n",
    "    y_positioning_loss_matrix = tf.square(y[:, :, :, 1::2] - pos_predictions) * (y[:, :, :, :1]) * (y[:, :, :, 1::2] + 0.069)\n",
    "    y_positioning_loss = tf.reduce_sum(y_positioning_loss_matrix) / tf.reduce_sum(y[:, :, :, 1::2]) * 0.5\n",
    "    \n",
    "    y_positioning_angle_loss_matrix = tf.square(tf.minimum(tf.abs(y[:, :, :, 2::2] - angle_predictions), tf.minimum(tf.abs(y[:, :, :, 2::2] - angle_predictions - 1), tf.abs(y[:, :, :, 2::2] - angle_predictions + 1)))) * (y[:, :, :, 1::2])\n",
    "    y_positioning_angle_loss = tf.reduce_sum(y_positioning_angle_loss_matrix) / tf.reduce_sum(y[:, :, :, 1::2]) * 20\n",
    "    \n",
    "    loss = timing_loss + y_positioning_loss + y_positioning_angle_loss\n",
    "\n",
    "    return timing_loss, y_positioning_loss, y_positioning_angle_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 = tf.constant(np.array([[[[1, 0, 0, 1, 0.5, 0, 0, 0, 0], [1, 1, 0.5, 0, 0, 0, 0, 0, 0]]]], dtype=np.float32))\n",
    "# v21 = tf.constant(np.array([[[[[1], [1]]]]], dtype=np.float32))\n",
    "# v22 = tf.constant(np.array([[[[1, 1, 0, 0], [1, 0, 0, 0]]]], dtype=np.float32))\n",
    "# v23 = tf.constant(np.array([[[[0.125, 0.5, 0, 0], [0.5, 0, 0, 0]]]], dtype=np.float32))\n",
    "# timing_loss, y_positioning_loss, y_positioning_angle_loss, loss = custom_loss(v1, (v21, v22, v23))\n",
    "# print(f\"timing_loss: {timing_loss}\")\n",
    "# print(f\"y_positioning_loss: {y_positioning_loss}\")\n",
    "# print(f\"y_positioning_angle_loss: {y_positioning_angle_loss}\")\n",
    "# print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, optimizer, data):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, y = data\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model([x1, x2, x3, x7, x8, y[:, :, :, :1]], training=True)\n",
    "        # with tf.device('/CPU:0'):\n",
    "        timing_loss, positioning_loss, angle_loss, loss = custom_loss(y, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    metric_train_timing_loss(timing_loss)\n",
    "    metric_train_pos_loss(positioning_loss)\n",
    "    metric_train_angle_loss(angle_loss)\n",
    "    metric_train_loss(loss)\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, data):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, y = data\n",
    "    \n",
    "    predictions = model([x1, x2, x3, x7, x8, y[:, :, :, :1]], training=False)\n",
    "    # with tf.device('/CPU:0'):\n",
    "    timing_loss, positioning_loss, angle_loss, loss = custom_loss(y, predictions)\n",
    "        \n",
    "    metric_val_timing_loss(timing_loss)\n",
    "    metric_val_pos_loss(positioning_loss)\n",
    "    metric_val_angle_loss(angle_loss)\n",
    "    metric_val_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results validation\n",
    "\n",
    "- specify the correct folder with maps for which you would want to generate the map\n",
    "- add maps that you want to use for testing, better to avoid using the maps that already exist in the training dataset to avoid false positives of AI learning a specific map\n",
    "- add an Expert diff if doesn't exist, currently hardcoded to just override the Expert diff to avoid setting up all the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_validation(timing_threshhold, epoch, acc_prediction, speed_prediction):\n",
    "    base_validation_path = \"./validation\"\n",
    "    os.makedirs(base_validation_path, exist_ok=True)\n",
    "    \n",
    "    validation_map = \"mazule\"\n",
    "    validation_map = \"isaidthat_DA42AF71F4CA5AD280C3F69BCA0BD6C6D1CDA06E\"\n",
    "    validation_map = \"DA42AF71F4CA5AD280C3F69BCA0BD6C6D1CDA06E\"\n",
    "    validation_map_dir = f\"{base_validation_path}/{validation_map}\"\n",
    "    (song_data, segment_duration), diffs = load_map(validation_map_dir)\n",
    "    \n",
    "    \n",
    "    angle_to_direction = {\n",
    "        180:0,\n",
    "        0:1,\n",
    "        90:2,\n",
    "        270:3,\n",
    "        135:4,\n",
    "        225:5,\n",
    "        45:6,\n",
    "        315:7\n",
    "    }\n",
    "    direction_to_angle = {\n",
    "        0: 180,\n",
    "        1: 0,\n",
    "        2: 90,\n",
    "        3: 270,\n",
    "        4: 135,\n",
    "        5: 225,\n",
    "        6: 45,\n",
    "        7: 315\n",
    "    }\n",
    "\n",
    "\n",
    "    def get_note_angle(direction):\n",
    "        return direction_to_angle[direction] / 360\n",
    "    \n",
    "    def get_note_direction(angle):\n",
    "        angle = int(angle * 360)\n",
    "        if angle % 45 > 22.5:\n",
    "            angle += 45\n",
    "        angle = (angle - angle % 45) % 360\n",
    "        return angle_to_direction[angle]\n",
    "\n",
    "    def validate_model(song_data, segment_duration, timing_threshhold, positioning_threshhold, intensity_1, intensity_2, acc_prediction, speed_prediction, note_pos_count):\n",
    "        context_length = 1\n",
    "        prediction_note_count = context_length * 40\n",
    "        prediction_note_time_length = context_length / prediction_note_count\n",
    "\n",
    "        context_steps = int(context_length / segment_duration) + 1\n",
    "        step_size = context_steps\n",
    "        \n",
    "        generated_notes = []\n",
    "        max_val_timing = 0\n",
    "        max_val_positioning = 0\n",
    "        \n",
    "        zero_notes = 1\n",
    "        one_notes = 1\n",
    "        \n",
    "        prev_note_segment = ([[0]*25 for i in range(prediction_note_count)], [[0]*25 for i in range(prediction_note_count)])\n",
    "        prev_audio_segment = song_data[:, :context_steps, :]\n",
    "        with tqdm(range(context_steps, song_data.shape[1] - context_steps, step_size)) as _tqdm:\n",
    "          for i in _tqdm:\n",
    "            curr_time = i * segment_duration\n",
    "            \n",
    "            x_context_prev_audio = prev_audio_segment\n",
    "            x_context_prev_notes = prev_note_segment\n",
    "            x_context_audio = song_data[:, i:i+context_steps, :]\n",
    "            timing_prediction, placement_prediction, placement_angle_prediction = model([np.array([x_context_prev_audio]), np.array([x_context_prev_notes]), np.array([x_context_audio]), np.array([acc_prediction + (random.random() - 0.5) * 0.1]), np.array([speed_prediction + (random.random() - 0.5) * 0.1]), np.array([[[[0]]*40, [[0]]*40]])], training=False)\n",
    "            timing_prediction = tf.where(timing_prediction > timing_threshhold, 1, 0)\n",
    "            _timing_prediction, placement_prediction, placement_angle_prediction = model([np.array([x_context_prev_audio]), np.array([x_context_prev_notes]), np.array([x_context_audio]), np.array([acc_prediction + (random.random() - 0.5) * 0.1]), np.array([speed_prediction + (random.random() - 0.5) * 0.1]), timing_prediction], training=False)\n",
    "            timing_prediction = np.array(timing_prediction[0])\n",
    "            placement_prediction = np.array(placement_prediction[0])\n",
    "            placement_angle_prediction = np.array(placement_angle_prediction[0])\n",
    "            \n",
    "            \n",
    "            x_context_prev_audio = x_context_audio\n",
    "            prev_note_segment = ([[0]*25 for i in range(prediction_note_count)], [[0]*25 for i in range(prediction_note_count)])\n",
    "\n",
    "            # I use them to find values that would generate a reasonable number of notes.\n",
    "            # Small adjustments to the model and it's loss function can significantly shift the actual number values.\n",
    "            # if max_val_timing < np.max(timing_prediction):\n",
    "            #     max_val_timing = np.max(timing_prediction)\n",
    "            #     print(f\"max_timing: {max_val_timing}\")\n",
    "                \n",
    "                # if max_val_positioning < np.max(positioning_prediction):\n",
    "                #     max_val_positioning = np.max(positioning_prediction)\n",
    "                #     print(f\"max_positioning: {max_val_positioning}\")\n",
    "            \n",
    "            for j in range(prediction_note_count):\n",
    "                for color in range(2):\n",
    "                    curr_note_time = curr_time + j * prediction_note_time_length\n",
    "                    prediction_timing = timing_prediction[color][j][0]\n",
    "                    if prediction_timing < timing_threshhold:\n",
    "                        continue\n",
    "                    prediction_positioning = placement_prediction[color][j]\n",
    "                    prediction_angle = placement_angle_prediction[color][j]\n",
    "                    \n",
    "                    # prediction_positioning[:12] = prediction_positioning[:12] * (one_notes / (zero_notes + one_notes + 0.00001))\n",
    "                    # prediction_positioning[12:] = prediction_positioning[12:] * (zero_notes / (zero_notes + one_notes + 0.00001))\n",
    "\n",
    "                    # Place only 1 note per timing or to place many notes. More than 1 note can get super repetitive more easily, but both are of quite poor quality so far.\n",
    "                    max_one_note_per_placement = True\n",
    "                    if max_one_note_per_placement:\n",
    "                        note_prediction_iter = np.argmax(prediction_positioning)\n",
    "                        prediction_positioning_enumerated = [(note_prediction_iter, prediction_positioning[note_prediction_iter], prediction_angle[note_prediction_iter])]\n",
    "                    else:\n",
    "                        prediction_positioning_enumerated = [(i, note_prediction, prediction_angle[i]) for i, note_prediction in enumerate(prediction_positioning) if note_prediction > positioning_threshhold]\n",
    "\n",
    "                    for note_prediction_iter, note_prediction, angle_prediction in prediction_positioning_enumerated:\n",
    "                            line_layer = note_prediction_iter % 3\n",
    "                            line_index = int(note_prediction_iter / 3) % 4\n",
    "                            direction = get_note_direction(angle_prediction)\n",
    "                            generated_notes.append(Note(curr_note_time, line_index, line_layer, color, direction))\n",
    "                            if color == 0:\n",
    "                                zero_notes += 1\n",
    "                            else:\n",
    "                                one_notes += 1\n",
    "                            prev_note_segment[color][j][0] = 1\n",
    "                            prev_note_segment[color][j][1 + note_prediction_iter * 2] = 1\n",
    "                            prev_note_segment[color][j][1 + note_prediction_iter * 2 + 1] = get_note_angle(direction)\n",
    "            if len(generated_notes) > 0:\n",
    "                average_notes_per_second = len(generated_notes)/generated_notes[-1].time\n",
    "            else:\n",
    "                average_notes_per_second = -1\n",
    "            _tqdm.set_postfix(average_notes_per_second=average_notes_per_second)\n",
    "        \n",
    "        generated_notes.sort(key=lambda note: note.time)\n",
    "        return generated_notes\n",
    "\n",
    "    intensity_timings_per_second = 7 # model input for number of correct timings per second\n",
    "    intensity_notes_per_second = intensity_timings_per_second # model input for sum of '1's in the prediction segment. Increasing this value should result in more stacks and sliders.\n",
    "    note_pos_count = 3\n",
    "    generated_notes = validate_model(song_data, segment_duration, timing_threshhold=timing_threshhold, positioning_threshhold=0.45, intensity_1=intensity_timings_per_second, intensity_2=intensity_notes_per_second/20, acc_prediction=acc_prediction, speed_prediction=speed_prediction, note_pos_count=note_pos_count/10)\n",
    "\n",
    "    if len(generated_notes) > 0:\n",
    "        average_notes_per_second = len(generated_notes)/generated_notes[-1].time\n",
    "    else:\n",
    "        average_notes_per_second = -1\n",
    "    \n",
    "    with open(validation_map_dir + \"/Info.dat\", \"rb\") as f:\n",
    "        info_json = json.load(f)\n",
    "        bpm = info_json[\"_beatsPerMinute\"]\n",
    "        \n",
    "    with open(validation_map_dir + \"/ExpertStandard.dat\", \"rb\") as f:\n",
    "        diff_json = json.load(f)\n",
    "\n",
    "    diff_json[\"_notes\"] = [{\"_time\": note.time / 60 * bpm, \"_lineIndex\": int(note.lineIndex), \"_lineLayer\": int(note.lineLayer), \"_type\": int(note.type), \"_cutDirection\": int(note.direction)} for note in generated_notes]\n",
    "    if len(diff_json[\"_notes\"]) == 0:\n",
    "        diff_json[\"_notes\"] = [{\"_time\": 1, \"_lineIndex\": 0, \"_lineLayer\": 0, \"_cutDirection\": 0, \"_type\": 0}]\n",
    "    with open(validation_map_dir + \"/ExpertStandard.dat\", \"w\") as f:\n",
    "        json.dump(diff_json, f)\n",
    "        \n",
    "    shutil.make_archive(f\"{validation_map_dir}q{epoch}q{timing_threshhold}q{average_notes_per_second}q{acc_prediction}q{speed_prediction}\", 'zip', validation_map_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch train: 2: : 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch train: 2: : 1766batch [06:48,  4.33batch/s, angle_loss=0.112, loss=0.334, pos_loss=0.0991, timing_loss=0.123]\n",
      "Epoch val: 2: : 208batch [00:27,  7.61batch/s, angle_loss=0.109, loss=0.332, pos_loss=0.0965, timing_loss=0.126]\n",
      "100%|██████████| 169/169 [00:36<00:00,  4.68it/s, average_notes_per_second=15.5]\n",
      "100%|██████████| 169/169 [00:36<00:00,  4.57it/s, average_notes_per_second=10.3]\n",
      "Epoch train: 3: : 1766batch [06:45,  4.35batch/s, angle_loss=0.105, loss=0.325, pos_loss=0.098, timing_loss=0.122] \n",
      "Epoch val: 3: : 208batch [00:18, 11.50batch/s, angle_loss=0.106, loss=0.329, pos_loss=0.0975, timing_loss=0.126]\n",
      "100%|██████████| 169/169 [00:35<00:00,  4.75it/s, average_notes_per_second=6.45]\n",
      "100%|██████████| 169/169 [00:37<00:00,  4.54it/s, average_notes_per_second=5.43]\n",
      "Epoch train: 4: : 1766batch [07:06,  4.14batch/s, angle_loss=0.0959, loss=0.311, pos_loss=0.0962, timing_loss=0.119]\n",
      "Epoch val: 4: : 208batch [00:18, 11.33batch/s, angle_loss=0.0992, loss=0.319, pos_loss=0.0946, timing_loss=0.125]\n",
      "100%|██████████| 127/127 [00:26<00:00,  4.76it/s, average_notes_per_second=7.54]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.62it/s, average_notes_per_second=5.93]\n",
      "Epoch train: 5: : 1766batch [06:34,  4.47batch/s, angle_loss=0.0933, loss=0.308, pos_loss=0.0958, timing_loss=0.118]\n",
      "Epoch val: 5: : 208batch [00:19, 10.79batch/s, angle_loss=0.0964, loss=0.315, pos_loss=0.0941, timing_loss=0.124]\n",
      "100%|██████████| 127/127 [00:26<00:00,  4.73it/s, average_notes_per_second=6.32]\n",
      "100%|██████████| 127/127 [00:29<00:00,  4.34it/s, average_notes_per_second=2.15]\n",
      "Epoch train: 6: : 1766batch [06:20,  4.64batch/s, angle_loss=0.089, loss=0.301, pos_loss=0.0949, timing_loss=0.117] \n",
      "Epoch val: 6: : 208batch [00:18, 11.04batch/s, angle_loss=0.0941, loss=0.311, pos_loss=0.0937, timing_loss=0.123]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.61it/s, average_notes_per_second=0.863]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.61it/s, average_notes_per_second=5.69]\n",
      "Epoch train: 7: : 1766batch [06:23,  4.61batch/s, angle_loss=0.0878, loss=0.299, pos_loss=0.0947, timing_loss=0.116]\n",
      "Epoch val: 7: : 208batch [00:19, 10.81batch/s, angle_loss=0.0932, loss=0.31, pos_loss=0.0934, timing_loss=0.123] \n",
      "100%|██████████| 127/127 [00:27<00:00,  4.65it/s, average_notes_per_second=6.99]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.67it/s, average_notes_per_second=4.68]\n",
      "Epoch train: 8: : 1766batch [06:56,  4.24batch/s, angle_loss=0.0866, loss=0.297, pos_loss=0.0945, timing_loss=0.116]\n",
      "Epoch val: 8: : 208batch [00:24,  8.64batch/s, angle_loss=0.0929, loss=0.309, pos_loss=0.0932, timing_loss=0.123]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.57it/s, average_notes_per_second=0.895]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.60it/s, average_notes_per_second=0.621]\n",
      "Epoch train: 9: : 1766batch [08:24,  3.50batch/s, angle_loss=0.0862, loss=0.297, pos_loss=0.0945, timing_loss=0.116]\n",
      "Epoch val: 9: : 208batch [00:18, 11.21batch/s, angle_loss=0.0928, loss=0.309, pos_loss=0.0932, timing_loss=0.123]\n",
      "100%|██████████| 127/127 [00:26<00:00,  4.73it/s, average_notes_per_second=2.49]\n",
      "100%|██████████| 127/127 [00:27<00:00,  4.66it/s, average_notes_per_second=7.07]\n",
      "Epoch train: 10: : 1766batch [07:00,  4.20batch/s, angle_loss=0.0858, loss=0.296, pos_loss=0.0944, timing_loss=0.116]\n",
      "Epoch val: 10: : 208batch [00:18, 11.08batch/s, angle_loss=0.0928, loss=0.309, pos_loss=0.0932, timing_loss=0.123]\n",
      "100%|██████████| 171/171 [00:36<00:00,  4.63it/s, average_notes_per_second=2.58]\n",
      "100%|██████████| 171/171 [00:37<00:00,  4.57it/s, average_notes_per_second=6.46]\n",
      "Epoch train: 11: : 1766batch [06:45,  4.36batch/s, angle_loss=0.0852, loss=0.295, pos_loss=0.0944, timing_loss=0.116]\n",
      "Epoch val: 11: : 208batch [00:18, 11.31batch/s, angle_loss=0.0927, loss=0.308, pos_loss=0.0932, timing_loss=0.123]\n",
      "100%|██████████| 171/171 [00:36<00:00,  4.68it/s, average_notes_per_second=10.1]\n",
      "100%|██████████| 171/171 [00:37<00:00,  4.56it/s, average_notes_per_second=1.87]\n",
      "Epoch train: 12: : 338batch [01:56,  2.90batch/s, angle_loss=0.0871, loss=0.3, pos_loss=0.0944, timing_loss=0.118]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\bs-map-generator\\src\\train.ipynb Cell 24\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m step, data \u001b[39min\u001b[39;00m _tqdm:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         train_step(model, optimizer, data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         _tqdm\u001b[39m.\u001b[39mset_postfix(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             timing_loss\u001b[39m=\u001b[39mmetric_train_timing_loss\u001b[39m.\u001b[39;49mresult()\u001b[39m.\u001b[39;49mnumpy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             pos_loss\u001b[39m=\u001b[39mmetric_train_pos_loss\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             angle_loss\u001b[39m=\u001b[39mmetric_train_angle_loss\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m             loss\u001b[39m=\u001b[39mmetric_train_loss\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mnumpy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mval_ds\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m() \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mval_ds\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mglobals\u001b[39m():\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/bs-map-generator/src/train.ipynb#X32sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(val_ds\u001b[39m.\u001b[39menumerate(), unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m _tqdm:\n",
      "File \u001b[1;32mc:\\Users\\tarim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\tarim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2, 15):\n",
    "    metric_train_timing_loss.reset_states()\n",
    "    metric_train_pos_loss.reset_states()\n",
    "    metric_train_angle_loss.reset_states()\n",
    "    metric_train_loss.reset_states()\n",
    "    metric_val_timing_loss.reset_states()\n",
    "    metric_val_pos_loss.reset_states()\n",
    "    metric_val_angle_loss.reset_states()\n",
    "    metric_val_loss.reset_states()\n",
    "\n",
    "    if epoch == 0:\n",
    "        optimizer.learning_rate.assign(0.001)\n",
    "    elif epoch == 2:\n",
    "        optimizer.learning_rate.assign(0.00025)\n",
    "    elif epoch == 4:\n",
    "        optimizer.learning_rate.assign(0.0001)\n",
    "    elif epoch == 6:\n",
    "        optimizer.learning_rate.assign(0.000025)\n",
    "    elif epoch == 8:\n",
    "        optimizer.learning_rate.assign(0.00001)\n",
    "    elif epoch == 11:\n",
    "        optimizer.learning_rate.assign(0.0000025)\n",
    "    \n",
    "    with tqdm(train_ds.enumerate(), unit=\"batch\") as _tqdm:\n",
    "        _tqdm.set_description(f\"Epoch train: {epoch}\")\n",
    "        for step, data in _tqdm:\n",
    "            train_step(model, optimizer, data)\n",
    "            _tqdm.set_postfix(\n",
    "                timing_loss=metric_train_timing_loss.result().numpy(),\n",
    "                pos_loss=metric_train_pos_loss.result().numpy(),\n",
    "                angle_loss=metric_train_angle_loss.result().numpy(),\n",
    "                loss=metric_train_loss.result().numpy(),\n",
    "            )\n",
    "    \n",
    "    if 'val_ds' in locals() or 'val_ds' in globals():\n",
    "        with tqdm(val_ds.enumerate(), unit=\"batch\") as _tqdm:\n",
    "            _tqdm.set_description(f\"Epoch val: {epoch}\")\n",
    "            for step, data in _tqdm:\n",
    "                val_step(model, data)\n",
    "                _tqdm.set_postfix(\n",
    "                    timing_loss=metric_val_timing_loss.result().numpy(),\n",
    "                    pos_loss=metric_val_pos_loss.result().numpy(),\n",
    "                    angle_loss=metric_val_angle_loss.result().numpy(),\n",
    "                    loss=metric_val_loss.result().numpy(),\n",
    "                )\n",
    "    \n",
    "    full_validation(0.825 + (random.random() - 0.5)*0.2, epoch, 0.775 + (random.random() - 0.5)*0.25, 0.35 + (random.random() - 0.5)*0.25)\n",
    "    full_validation(0.825 + (random.random() - 0.5)*0.2, epoch, 0.775 + (random.random() - 0.5)*0.25, 0.35 + (random.random() - 0.5)*0.25)\n",
    "\n",
    "# Epoch train: 2: : 2005batch [07:22,  4.53batch/s, angle_loss=0.172, loss=0.364, pos_loss=0.0891, timing_loss=0.103]\n",
    "# Epoch val: 2: : 237batch [00:28,  8.41batch/s, angle_loss=0.153, loss=0.34, pos_loss=0.0838, timing_loss=0.103] \n",
    "# Epoch train: 3: : 2005batch [07:47,  4.29batch/s, angle_loss=0.138, loss=0.324, pos_loss=0.0848, timing_loss=0.102]\n",
    "# Epoch val: 3: : 237batch [00:20, 11.42batch/s, angle_loss=0.124, loss=0.308, pos_loss=0.0813, timing_loss=0.103]\n",
    "# Epoch train: 4: : 2005batch [08:18,  4.02batch/s, angle_loss=0.115, loss=0.296, pos_loss=0.0818, timing_loss=0.099] \n",
    "# Epoch val: 4: : 237batch [00:28,  8.29batch/s, angle_loss=0.114, loss=0.295, pos_loss=0.0799, timing_loss=0.101]\n",
    "# Epoch train: 5: : 2005batch [07:33,  4.42batch/s, angle_loss=0.109, loss=0.288, pos_loss=0.0812, timing_loss=0.0981]\n",
    "# Epoch val: 5: : 237batch [00:21, 11.24batch/s, angle_loss=0.109, loss=0.289, pos_loss=0.0801, timing_loss=0.1]  \n",
    "# Epoch train: 6: : 2005batch [07:30,  4.45batch/s, angle_loss=0.103, loss=0.28, pos_loss=0.0802, timing_loss=0.097]  \n",
    "# Epoch val: 6: : 237batch [00:21, 11.06batch/s, angle_loss=0.106, loss=0.284, pos_loss=0.0789, timing_loss=0.0996]\n",
    "# Epoch train: 7: : 2005batch [08:00,  4.18batch/s, angle_loss=0.101, loss=0.278, pos_loss=0.08, timing_loss=0.0967]  \n",
    "# Epoch val: 7: : 237batch [00:21, 11.20batch/s, angle_loss=0.105, loss=0.283, pos_loss=0.0786, timing_loss=0.0993]\n",
    "# Epoch train: 8: : 53batch [00:38,  1.39batch/s, angle_loss=0.101, loss=0.283, pos_loss=0.0799, timing_loss=0.102] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./goodmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./goodmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"./goodmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:39<00:00,  4.30it/s, average_notes_per_second=7.89]\n"
     ]
    }
   ],
   "source": [
    "full_validation(0.8 + (random.random() - 0.5)*0.1, epoch, 0.775 + (random.random() - 0.5)*0.15, 0.3 + (random.random() - 0.5)*0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
