{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import random\n",
    "from data_loader import full_load_map, data_dir, load_map, Note\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1470258369\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_multi_process(map_folders):\n",
    "    map_folders = [map_folder.decode('UTF-8') for map_folder in map_folders]\n",
    "    max_workers = 18\n",
    "    items_in_queue = max_workers * 5\n",
    "    queued_maps = items_in_queue\n",
    "    cancel = False\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        map_tasks = [(executor.submit(full_load_map, map_folder), map_folder) for map_folder in map_folders[:items_in_queue]]\n",
    "        while len(map_tasks) > 0:\n",
    "            map_task, map_folder = map_tasks.pop(0)\n",
    "            try:\n",
    "                if cancel:\n",
    "                    map_task.cancel()\n",
    "                    continue\n",
    "                results = map_task.result()\n",
    "                for result in results:\n",
    "                    x_context_prev_audio, x_context_prev_notes, x_context_audio, y_context_notes, z_timing_counts, z_note_counts, z_note_pos_counts, z_acc_prediction, z_speed_prediction = result\n",
    "                    yield (x_context_prev_audio), (x_context_prev_notes), (x_context_audio), z_timing_counts, z_note_counts/20, z_note_pos_counts/10, z_acc_prediction, z_speed_prediction, (y_context_notes)\n",
    "            except InterruptedError as ke:\n",
    "                cancel = True\n",
    "            except Exception as exc:\n",
    "                if str(exc) != \"'_version'\" and str(exc) != 'not v2':\n",
    "                    print(map_folder)\n",
    "                    print(exc)\n",
    "                    traceback.print_exc()\n",
    "            finally:\n",
    "                if not cancel:\n",
    "                    queued_maps += 1\n",
    "                    if queued_maps < len(map_folders):\n",
    "                        map_tasks.append((executor.submit(full_load_map, map_folders[queued_maps]), map_folders[queued_maps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ds_for_files(map_folders, batch_size, name, cache=False, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_generator(data_generator_multi_process, args=[map_folders], output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 2, 87, 129), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 40, 25), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 87, 129), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2, 40, 25), dtype=tf.float32),\n",
    "        # tf.TensorSpec(shape=(None, 1025, 44), dtype=tf.float32),\n",
    "        # tf.TensorSpec(shape=(None, 35), dtype=tf.float32),\n",
    "    ))\n",
    "    ds = ds.flat_map(lambda x1, x2, x3, x4, x5, x6, x7, x8, y: tf.data.Dataset.from_tensor_slices((x1, x2, x3, x4, x5, x6, x7, x8, y)))\n",
    "    ds = ds.prefetch(20000)\n",
    "\n",
    "    if cache:\n",
    "        # ds = ds.cache()\n",
    "        ds = ds.cache(f\"./somethingsomething/{name}\")\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(25000, reshuffle_each_iteration=True)\n",
    "        # ds = ds.shuffle(len([v for v in ds]), reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(256)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I currently cache the entire dataset, since the data loading part is quite compute intensive. Added a limit of 50 maps to avoid running out of ram on a test run.\n",
    "maps = [path.replace(\"\\\\\", \"/\") for path in glob.glob(\"../data/maps/*\")]\n",
    "random.shuffle(maps)\n",
    "maps = maps[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "val_split = 0.1\n",
    "train_ds = create_ds_for_files(maps[int(len(maps)*val_split):], batch_size, \"train\", True, True)\n",
    "val_ds = create_ds_for_files(maps[:int(len(maps)*val_split)], batch_size, \"val\", True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload the dataset into cache to keep the data loading errors away from the training logs\n",
    "discard_val = 0\n",
    "for v in tqdm(train_ds):\n",
    "    discard_val = discard_val + 1\n",
    "\n",
    "for v in tqdm(val_ds):\n",
    "    discard_val = discard_val + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per position loss balance, might not be relevent with the updatd note format\n",
    "# # with tf.device('/CPU:0'):\n",
    "# out_value_counts = tf.constant([0]*49, dtype=tf.float32)\n",
    "# for v_batch in tqdm(train_ds):\n",
    "#     out_value_counts = out_value_counts + tf.reduce_sum(v_batch[-1], axis=[0, 1])\n",
    "# # for i, ovc in enumerate(out_value_counts):\n",
    "# #     print(f\"{(i-1)} {ovc}\")\n",
    "# note_poss_loss_balance = tf.expand_dims(tf.expand_dims(1/tf.maximum(out_value_counts[1:] * (1/np.max(out_value_counts[1:])*10), 1), 0), 0)\n",
    "# note_poss_loss_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_block():\n",
    "    input_audio = tf.keras.Input(shape=(87, 129, 1), dtype=\"float32\")\n",
    "    l = input_audio\n",
    "    l = tf.keras.layers.Conv2D(128, 5, activation=\"relu\", padding=\"same\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(l)\n",
    "    l = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(1, 2))(l)\n",
    "    l = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(l)\n",
    "    l = tf.keras.layers.MaxPooling2D(pool_size=(1, 2))(l)\n",
    "    l = tf.keras.layers.Reshape((40, -1))(l)\n",
    "    l = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(128, activation=\"tanh\"))(l)\n",
    "    return tf.keras.Model(input_audio, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_block_stereo():\n",
    "    l_audio_block = audio_block()\n",
    "    \n",
    "    input_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    l = input_audio\n",
    "    l = tf.keras.layers.TimeDistributed(l_audio_block)(l)\n",
    "    l = tf.keras.layers.Reshape((40, -1))(l)\n",
    "    l = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(l)\n",
    "    l = tf.keras.layers.LSTM(64, return_sequences=True)(l)\n",
    "    return tf.keras.Model(input_audio, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_positioning_block():\n",
    "    input_timings = tf.keras.Input(shape=(2, 40, 1), dtype=\"float32\")\n",
    "    input_features = tf.keras.Input(shape=(40, 128), dtype=\"float32\")\n",
    "    \n",
    "    l_timings = tf.keras.layers.Reshape((40, -1))(input_timings)\n",
    "\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_timings, input_features])\n",
    "    l = tf.keras.layers.LSTM(256, return_sequences=True)(l)\n",
    "    l = tf.keras.layers.LSTM(256, return_sequences=True)(l)\n",
    "    l_pos_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(24, activation=\"sigmoid\"))(l)\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_pos_out, l])\n",
    "    l = tf.keras.layers.LSTM(128, return_sequences=True)(l)\n",
    "    l = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(l)\n",
    "    l_angle_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(24, activation=\"relu\"))(l)\n",
    "    \n",
    "    l_pos_out = tf.keras.layers.Reshape((2, 40, -1))(l_pos_out)\n",
    "    l_angle_out = tf.keras.layers.Reshape((2, 40, -1))(l_angle_out)\n",
    "    \n",
    "    return tf.keras.Model([input_timings, input_features], [l_pos_out, l_angle_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    input_prev_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    input_prev_notes = tf.keras.Input(shape=(2, 40, 25), dtype=\"float32\")\n",
    "    input_audio = tf.keras.Input(shape=(2, 87, 129, 1), dtype=\"float32\")\n",
    "    input_acc_prediction = tf.keras.Input(shape=(1), dtype=\"float32\")\n",
    "    input_speed_prediction = tf.keras.Input(shape=(1), dtype=\"float32\")\n",
    "    input_y_note_timings = tf.keras.Input(shape=(2, 40, 1), dtype=\"float32\")\n",
    "\n",
    "    audio_l = audio_block_stereo()\n",
    "\n",
    "    l_prev_audio = audio_l(input_prev_audio)\n",
    "    l_audio = audio_l(input_audio)\n",
    "    \n",
    "    l_prev_notes = tf.keras.layers.Reshape((40, -1))(input_prev_notes)\n",
    "    \n",
    "    l_prev = tf.keras.layers.Concatenate(axis=2)([l_prev_audio, l_prev_notes])\n",
    "    l_prev = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(l_prev)\n",
    "    l_prev = tf.keras.layers.LSTM(64)(l_prev)\n",
    "    \n",
    "    l_input_acc_prediction = tf.keras.layers.RepeatVector(40)(input_acc_prediction)\n",
    "    l_input_speed_prediction = tf.keras.layers.RepeatVector(40)(input_speed_prediction)\n",
    "    l_prev = tf.keras.layers.RepeatVector(40)(l_prev)\n",
    "    l = tf.keras.layers.Concatenate(axis=2)([l_audio, l_prev, l_input_acc_prediction, l_input_speed_prediction])\n",
    "    l = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(l)\n",
    "    l = tf.keras.layers.LSTM(128, return_sequences=True)(l)\n",
    "    l_timings_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"sigmoid\"))(l)\n",
    "    l_timings_out = tf.keras.layers.Reshape((2, 40, -1))(l_timings_out)\n",
    "\n",
    "    note_positioning_l = note_positioning_block()\n",
    "    \n",
    "    l_pos_out, l_angle_out = note_positioning_l([input_y_note_timings, l])\n",
    "\n",
    "    model = tf.keras.Model(inputs = [input_prev_audio, input_prev_notes, input_audio, input_acc_prediction, input_speed_prediction, input_y_note_timings], outputs = [l_timings_out, l_pos_out, l_angle_out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 2, 87, 129,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 2, 87, 129,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 2, 40, 25)]  0           []                               \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 40, 64)       741760      ['input_11[0][0]',               \n",
      "                                                                  'input_13[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 40, 50)       0           ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 40, 114)      0           ['model_5[0][0]',                \n",
      "                                                                  'reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 40, 128)     91648       ['concatenate_4[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 64)           49408       ['bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " repeat_vector_5 (RepeatVector)  (None, 40, 64)      0           ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 40, 1)       0           ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " repeat_vector_4 (RepeatVector)  (None, 40, 1)       0           ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 40, 130)      0           ['model_5[1][0]',                \n",
      "                                                                  'repeat_vector_5[0][0]',        \n",
      "                                                                  'repeat_vector_3[0][0]',        \n",
      "                                                                  'repeat_vector_4[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 40, 256)     265216      ['concatenate_5[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 (None, 40, 128)      197120      ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 40, 2)       258         ['lstm_14[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 2, 40, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 2, 40, 1)     0           ['time_distributed_8[0][0]']     \n",
      "                                                                                                  \n",
      " model_6 (Functional)           [(None, 2, 40, 12),  1176368     ['input_16[0][0]',               \n",
      "                                 (None, 2, 40, 12)]               'lstm_14[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,521,778\n",
      "Trainable params: 2,521,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timing_loss_metric = tf.keras.metrics.Mean(name='train_timing_loss')\n",
    "train_positioning_loss_metric = tf.keras.metrics.Mean(name='train_positioning_loss')\n",
    "train_y_positioning_loss_metric = tf.keras.metrics.Mean(name='train_y_positioning_loss')\n",
    "train_y_positioning_angle_loss_metric = tf.keras.metrics.Mean(name='train_y_positioning_angle_loss')\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "val_timing_loss_metric = tf.keras.metrics.Mean(name='val_timing_loss')\n",
    "val_positioning_loss_metric = tf.keras.metrics.Mean(name='val_positioning_loss')\n",
    "val_y_positioning_loss_metric = tf.keras.metrics.Mean(name='val_y_positioning_loss')\n",
    "val_y_positioning_angle_loss_metric = tf.keras.metrics.Mean(name='val_y_positioning_angle_loss')\n",
    "val_loss_metric = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss\n",
    "Calculates 2 separate values:\n",
    " - timing loss - simple loss based on when the notes were placed\n",
    " - positioning loss - loss based on the position and direction of the placed note, adjusted for the number of notes that appear in different positions to avoid a massive bias towards placing most commonly appearing notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_loss(y, predictions):\n",
    "    timing_predictions, pos_predictions, angle_predictions = predictions\n",
    "    \n",
    "    org_timing_loss_matrix = tf.square(y[:, :, :, :1] - timing_predictions) * (y[:, :, :, :1] + 0.069)\n",
    "    timing_loss_matrix = org_timing_loss_matrix\n",
    "    timing_loss = tf.reduce_mean(timing_loss_matrix) * 6.9\n",
    "    \n",
    "    # positioning_loss_matrix = tf.square(y[:, :, 1:] - positioning_predictions) * (y[:, :, :1]) * (y[:, :, 1:] * note_poss_loss_balance + 0.0169)\n",
    "    # positioning_loss = tf.reduce_sum(positioning_loss_matrix) / tf.reduce_sum(y[:, :, 1:]) * 0.5\n",
    "    \n",
    "    y_positioning_loss_matrix = tf.square(y[:, :, :, 1::2] - pos_predictions) * (y[:, :, :, :1]) * (y[:, :, :, 1::2] + 0.069)\n",
    "    y_positioning_loss = tf.reduce_sum(y_positioning_loss_matrix) / tf.reduce_sum(y[:, :, :, 1::2]) * 0.69\n",
    "    \n",
    "    y_positioning_angle_loss_matrix = tf.square(tf.minimum(tf.abs(y[:, :, :, 2::2] - angle_predictions), tf.minimum(tf.abs(y[:, :, :, 2::2] - angle_predictions + 1), tf.abs(y[:, :, :, 2::2] - angle_predictions - 1)))) * (y[:, :, :, 1::2])\n",
    "    y_positioning_angle_loss = tf.reduce_sum(y_positioning_angle_loss_matrix) / tf.reduce_sum(y[:, :, :, 1::2]) * 6.9\n",
    "    \n",
    "    loss = timing_loss + y_positioning_loss + y_positioning_angle_loss\n",
    "    return timing_loss, y_positioning_loss, y_positioning_angle_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, optimizer, data):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, y = data\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model([x1, x2, x3, x7, x8, y[:, :, :, :1]], training=True)\n",
    "        # predictions = model([x1, x2, x3, x4, x5, x6, x7, x8, y[:, :, :1]], training=True)\n",
    "        # with tf.device('/CPU:0'):\n",
    "        timing_loss, y_positioning_loss, y_positioning_angle_loss, loss = custom_loss(y, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_timing_loss_metric(timing_loss)\n",
    "    # train_positioning_loss_metric(positioning_loss)\n",
    "    train_y_positioning_loss_metric(y_positioning_loss)\n",
    "    train_y_positioning_angle_loss_metric(y_positioning_angle_loss)\n",
    "    train_loss_metric(loss)\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, data):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, y = data\n",
    "    \n",
    "    predictions = model([x1, x2, x3, x7, x8, y[:, :, :, :1]], training=False)\n",
    "    # predictions = model([x1, x2, x3, x4, x5, x6, x7, x8, y[:, :, :1]], training=False)\n",
    "    # with tf.device('/CPU:0'):\n",
    "    timing_loss, y_positioning_loss, y_positioning_angle_loss, loss = custom_loss(y, predictions)\n",
    "        \n",
    "    val_timing_loss_metric(timing_loss)\n",
    "    # val_positioning_loss_metric(positioning_loss)\n",
    "    val_y_positioning_loss_metric(y_positioning_loss)\n",
    "    val_y_positioning_angle_loss_metric(y_positioning_angle_loss)\n",
    "    val_loss_metric(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results validation\n",
    "\n",
    "- specify the correct folder with maps for which you would want to generate the map\n",
    "- add maps that you want to use for testing, better to avoid using the maps that already exist in the training dataset to avoid false positives of AI learning a specific map\n",
    "- add an Expert diff if doesn't exist, currently hardcoded to just override the Expert diff to avoid setting up all the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_validation(timing_threshhold, epoch, acc_prediction, speed_prediction):\n",
    "    base_validation_path = \"./validation\"\n",
    "    os.makedirs(base_validation_path, exist_ok=True)\n",
    "    \n",
    "    validation_map = \"mazule\"\n",
    "    validation_map = \"isaidthat_DA42AF71F4CA5AD280C3F69BCA0BD6C6D1CDA06E\"\n",
    "    validation_map = \"DA42AF71F4CA5AD280C3F69BCA0BD6C6D1CDA06E\"\n",
    "    validation_map_dir = f\"{base_validation_path}/{validation_map}\"\n",
    "    (song_data, segment_duration), diffs = load_map(validation_map_dir)\n",
    "    \n",
    "    \n",
    "    angle_to_direction = {\n",
    "        180:0,\n",
    "        0:1,\n",
    "        90:2,\n",
    "        270:3,\n",
    "        135:4,\n",
    "        225:5,\n",
    "        45:6,\n",
    "        315:7\n",
    "    }\n",
    "    direction_to_angle = {\n",
    "        0: 180,\n",
    "        1: 0,\n",
    "        2: 90,\n",
    "        3: 270,\n",
    "        4: 135,\n",
    "        5: 225,\n",
    "        6: 45,\n",
    "        7: 315\n",
    "    }\n",
    "\n",
    "\n",
    "    def get_note_angle(direction):\n",
    "        return direction_to_angle[direction] / 360\n",
    "    \n",
    "    def get_note_direction(angle):\n",
    "        angle = int(angle * 360)\n",
    "        angle = (angle - angle % 45) % 360\n",
    "        return angle_to_direction[angle]\n",
    "\n",
    "    def validate_model(song_data, segment_duration, timing_threshhold, positioning_threshhold, intensity_1, intensity_2, acc_prediction, speed_prediction, note_pos_count):\n",
    "        context_length = 1\n",
    "        prediction_note_count = context_length * 40\n",
    "        prediction_note_time_length = context_length / prediction_note_count\n",
    "\n",
    "        context_steps = int(context_length / segment_duration) + 1\n",
    "        step_size = context_steps\n",
    "        \n",
    "        generated_notes = []\n",
    "        max_val_timing = 0\n",
    "        max_val_positioning = 0\n",
    "        \n",
    "        zero_notes = 1\n",
    "        one_notes = 1\n",
    "        \n",
    "        prev_note_segment = ([[0]*25 for i in range(prediction_note_count)], [[0]*25 for i in range(prediction_note_count)])\n",
    "        prev_audio_segment = song_data[:, :context_steps, :]\n",
    "        with tqdm(range(context_steps, song_data.shape[1] - context_steps, step_size)) as _tqdm:\n",
    "          for i in _tqdm:\n",
    "            curr_time = i * segment_duration\n",
    "            \n",
    "            x_context_prev_audio = prev_audio_segment\n",
    "            x_context_prev_notes = prev_note_segment\n",
    "            x_context_audio = song_data[:, i:i+context_steps, :]\n",
    "            timing_prediction, placement_prediction, placement_angle_prediction = model([np.array([x_context_prev_audio]), np.array([x_context_prev_notes]), np.array([x_context_audio]), np.array([acc_prediction + (random.random() - 0.5) * 0.1]), np.array([speed_prediction + (random.random() - 0.5) * 0.1]), np.array([[[[0]]*40, [[0]]*40]])], training=False)\n",
    "            timing_prediction = tf.where(timing_prediction > timing_threshhold, 1, 0)\n",
    "            _timing_prediction, placement_prediction, placement_angle_prediction = model([np.array([x_context_prev_audio]), np.array([x_context_prev_notes]), np.array([x_context_audio]), np.array([acc_prediction + (random.random() - 0.5) * 0.1]), np.array([speed_prediction + (random.random() - 0.5) * 0.1]), timing_prediction], training=False)\n",
    "            timing_prediction = np.array(timing_prediction[0])\n",
    "            placement_prediction = np.array(placement_prediction[0])\n",
    "            placement_angle_prediction = np.array(placement_angle_prediction[0])\n",
    "            \n",
    "            \n",
    "            x_context_prev_audio = x_context_audio\n",
    "            prev_note_segment = ([[0]*25 for i in range(prediction_note_count)], [[0]*25 for i in range(prediction_note_count)])\n",
    "\n",
    "            # I use them to find values that would generate a reasonable number of notes.\n",
    "            # Small adjustments to the model and it's loss function can significantly shift the actual number values.\n",
    "            # if max_val_timing < np.max(timing_prediction):\n",
    "            #     max_val_timing = np.max(timing_prediction)\n",
    "            #     print(f\"max_timing: {max_val_timing}\")\n",
    "                \n",
    "                # if max_val_positioning < np.max(positioning_prediction):\n",
    "                #     max_val_positioning = np.max(positioning_prediction)\n",
    "                #     print(f\"max_positioning: {max_val_positioning}\")\n",
    "            \n",
    "            for j in range(prediction_note_count):\n",
    "                for color in range(2):\n",
    "                    curr_note_time = curr_time + j * prediction_note_time_length\n",
    "                    prediction_timing = timing_prediction[color][j][0]\n",
    "                    if prediction_timing < timing_threshhold:\n",
    "                        continue\n",
    "                    prediction_positioning = placement_prediction[color][j]\n",
    "                    prediction_angle = placement_angle_prediction[color][j]\n",
    "                    \n",
    "                    # prediction_positioning[:12] = prediction_positioning[:12] * (one_notes / (zero_notes + one_notes + 0.00001))\n",
    "                    # prediction_positioning[12:] = prediction_positioning[12:] * (zero_notes / (zero_notes + one_notes + 0.00001))\n",
    "\n",
    "                    # Place only 1 note per timing or to place many notes. More than 1 note can get super repetitive more easily, but both are of quite poor quality so far.\n",
    "                    max_one_note_per_placement = True\n",
    "                    if max_one_note_per_placement:\n",
    "                        note_prediction_iter = np.argmax(prediction_positioning)\n",
    "                        prediction_positioning_enumerated = [(note_prediction_iter, prediction_positioning[note_prediction_iter], prediction_angle[note_prediction_iter])]\n",
    "                    else:\n",
    "                        prediction_positioning_enumerated = [(i, note_prediction, prediction_angle[i]) for i, note_prediction in enumerate(prediction_positioning) if note_prediction > positioning_threshhold]\n",
    "\n",
    "                    for note_prediction_iter, note_prediction, angle_prediction in prediction_positioning_enumerated:\n",
    "                            line_layer = note_prediction_iter % 3\n",
    "                            line_index = int(note_prediction_iter / 3) % 4\n",
    "                            direction = get_note_direction(angle_prediction)\n",
    "                            generated_notes.append(Note(curr_note_time, line_index, line_layer, color, direction))\n",
    "                            if color == 0:\n",
    "                                zero_notes += 1\n",
    "                            else:\n",
    "                                one_notes += 1\n",
    "                            prev_note_segment[color][j][0] = 1\n",
    "                            prev_note_segment[color][j][1 + note_prediction_iter * 2] = 1\n",
    "                            prev_note_segment[color][j][1 + note_prediction_iter * 2 + 1] = get_note_angle(direction)\n",
    "            if len(generated_notes) > 0:\n",
    "                average_notes_per_second = len(generated_notes)/generated_notes[-1].time\n",
    "            else:\n",
    "                average_notes_per_second = -1\n",
    "            _tqdm.set_postfix(average_notes_per_second=average_notes_per_second)\n",
    "        \n",
    "        generated_notes.sort(key=lambda note: note.time)\n",
    "        return generated_notes\n",
    "\n",
    "    intensity_timings_per_second = 7 # model input for number of correct timings per second\n",
    "    intensity_notes_per_second = intensity_timings_per_second # model input for sum of '1's in the prediction segment. Increasing this value should result in more stacks and sliders.\n",
    "    note_pos_count = 3\n",
    "    generated_notes = validate_model(song_data, segment_duration, timing_threshhold=timing_threshhold, positioning_threshhold=0.45, intensity_1=intensity_timings_per_second, intensity_2=intensity_notes_per_second/20, acc_prediction=acc_prediction, speed_prediction=speed_prediction, note_pos_count=note_pos_count/10)\n",
    "\n",
    "    if len(generated_notes) > 0:\n",
    "        average_notes_per_second = len(generated_notes)/generated_notes[-1].time\n",
    "    else:\n",
    "        average_notes_per_second = -1\n",
    "    \n",
    "    with open(validation_map_dir + \"/Info.dat\", \"rb\") as f:\n",
    "        info_json = json.load(f)\n",
    "        bpm = info_json[\"_beatsPerMinute\"]\n",
    "        \n",
    "    with open(validation_map_dir + \"/ExpertStandard.dat\", \"rb\") as f:\n",
    "        diff_json = json.load(f)\n",
    "\n",
    "    diff_json[\"_notes\"] = [{\"_time\": note.time / 60 * bpm, \"_lineIndex\": int(note.lineIndex), \"_lineLayer\": int(note.lineLayer), \"_type\": int(note.type), \"_cutDirection\": int(note.direction)} for note in generated_notes]\n",
    "    if len(diff_json[\"_notes\"]) == 0:\n",
    "        diff_json[\"_notes\"] = [{\"_time\": 1, \"_lineIndex\": 0, \"_lineLayer\": 0, \"_cutDirection\": 0, \"_type\": 0}]\n",
    "    with open(validation_map_dir + \"/ExpertStandard.dat\", \"w\") as f:\n",
    "        json.dump(diff_json, f)\n",
    "        \n",
    "    shutil.make_archive(f\"{validation_map_dir}q{epoch}q{timing_threshhold}q{average_notes_per_second}q{acc_prediction}q{speed_prediction}\", 'zip', validation_map_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch train: 2: : 317batch [01:35,  4.91batch/s, loss=0.453, positioning_loss=0, positioning_y_angle_loss=0.176, positioning_y_loss=0.174, timing_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch train: 2: : 328batch [01:37,  4.64batch/s, loss=0.452, positioning_loss=0, positioning_y_angle_loss=0.176, positioning_y_loss=0.174, timing_loss=0.102]"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 15):\n",
    "    train_timing_loss_metric.reset_states()\n",
    "    train_positioning_loss_metric.reset_states()\n",
    "    train_y_positioning_loss_metric.reset_states()\n",
    "    train_y_positioning_angle_loss_metric.reset_states()\n",
    "    train_loss_metric.reset_states()\n",
    "    \n",
    "    val_timing_loss_metric.reset_states()\n",
    "    val_positioning_loss_metric.reset_states()\n",
    "    val_y_positioning_loss_metric.reset_states()\n",
    "    val_y_positioning_angle_loss_metric.reset_states()\n",
    "    val_loss_metric.reset_states()\n",
    "\n",
    "    if epoch == 0:\n",
    "        optimizer.learning_rate.assign(0.001)\n",
    "    elif epoch == 2:\n",
    "        optimizer.learning_rate.assign(0.00025)\n",
    "    elif epoch == 4:\n",
    "        optimizer.learning_rate.assign(0.0001)\n",
    "    elif epoch == 6:\n",
    "        optimizer.learning_rate.assign(0.000025)\n",
    "    elif epoch == 8:\n",
    "        optimizer.learning_rate.assign(0.00001)\n",
    "    elif epoch == 11:\n",
    "        optimizer.learning_rate.assign(0.0000025)\n",
    "    \n",
    "    with tqdm(train_ds.enumerate(), unit=\"batch\") as _tqdm:\n",
    "        _tqdm.set_description(f\"Epoch train: {epoch}\")\n",
    "        for step, data in _tqdm:\n",
    "            train_step(model, optimizer, data)\n",
    "            _tqdm.set_postfix(\n",
    "                timing_loss=train_timing_loss_metric.result().numpy(),\n",
    "                positioning_loss=train_positioning_loss_metric.result().numpy(),\n",
    "                positioning_y_loss=train_y_positioning_loss_metric.result().numpy(),\n",
    "                positioning_y_angle_loss=train_y_positioning_angle_loss_metric.result().numpy(),\n",
    "                loss=train_loss_metric.result().numpy(),\n",
    "            )\n",
    "    \n",
    "    if 'val_ds' in locals() or 'val_ds' in globals():\n",
    "        with tqdm(val_ds.enumerate(), unit=\"batch\") as _tqdm:\n",
    "            _tqdm.set_description(f\"Epoch val: {epoch}\")\n",
    "            for step, data in _tqdm:\n",
    "                val_step(model, data)\n",
    "                _tqdm.set_postfix(\n",
    "                    timing_loss=val_timing_loss_metric.result().numpy(),\n",
    "                    positioning_loss=val_positioning_loss_metric.result().numpy(),\n",
    "                    positioning_y_loss=val_y_positioning_loss_metric.result().numpy(),\n",
    "                    positioning_y_angle_loss=val_y_positioning_angle_loss_metric.result().numpy(),\n",
    "                    loss=val_loss_metric.result().numpy(),\n",
    "                )\n",
    "    \n",
    "    full_validation(0.825 + (random.random() - 0.5)*0.2, epoch, 0.775 + (random.random() - 0.5)*0.25, 0.35 + (random.random() - 0.5)*0.25)\n",
    "    full_validation(0.825 + (random.random() - 0.5)*0.2, epoch, 0.775 + (random.random() - 0.5)*0.25, 0.35 + (random.random() - 0.5)*0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
